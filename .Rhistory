cond <- cond + condition(runif(10), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(beg - Sys.time())
}
m <- c(100,1000,10000,100000, 1000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
fast
rm(list=ls())
set.seed(13112221)
library(parallel)
library(doSNOW)
n_cores <- detectCores()
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
stopping <- function(M){
beg <- Sys.time()
t_data <- rep(NA, M)
x <- runif(M)
for (m in 1:M){
t <- 1
cond <- condition(runif(10), t , x[m])
t <- t + cond
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(10), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(Sys.time() - beg)
}
m <- c(100,1000,10000,100000, 1000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
stopCluster(cl)
rm(list=ls())
set.seed(13112221)
n_cores <- detectCores()
n_cores
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
stopping <- function(M){
beg <- Sys.time()
t_data <- rep(NA, M)
x <- runif(M)
for (m in 1:M){
t <- 1
cond <- condition(runif(10), t , x[m])
t <- t + cond
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(10), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(Sys.time() - beg)
}
m <- c(100,1000,10000,100000, 1000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
fast
m <- c(100, 1000, 10000, 100000, 1000000, 10000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
rm(list=ls())
set.seed(13112221)
library(parallel)
library(doSNOW)
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
stopping <- function(M){
beg <- Sys.time()
t_data <- rep(NA, M)
x <- runif(M)
for (m in 1:M){
t <- 1
cond <- condition(runif(10), t , x[m])
t <- t + cond
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(10), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(Sys.time() - beg)
}
m <- c(100, 1000, 10000, 100000, 1000000, 10000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
stopCluster(cl)
fast
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
cl <- makeCluster(n_cores, type = 'SOCK')
n_cores <- detectCores()
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
stopping <- function(M){
beg <- Sys.time()
t_data <- rep(NA, M)
x <- runif(M)
for (m in 1:M){
t <- 1
cond <- condition(runif(10), t , x[m])
t <- t + cond
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(10), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(Sys.time() - beg)
}
m <- c(100, 1000, 10000, 100000, 1000000, 10000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
stopCluster(cl)
fast
rm(list=ls())
M <- 100000
t_data <- rep(NA, M)
x <- runif(M)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
for (m in 1:M){
t <- 1
cond <- condition(runif(10), t , x[m])
t <- t + cond
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(cond * 2), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
rm(list=ls())
M <- 10000000
t_data <- rep(NA, M)
x <- runif(M)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
for (m in 1:M){
t <- 1
cond <- condition(runif(10), t , x[m])
t <- t + cond
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(cond * 2), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
barplot(table(t_data), xlim = x(1,25))
barplot(table(t_data), xlim = c(1,25))
rm(list=ls())
set.seed(13112221)
library(parallel)
library(doSNOW)
n_cores <- detectCores()
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
stopping <- function(M){
beg <- Sys.time()
t_data <- rep(NA, M)
x <- runif(M)
for (m in 1:M){
t <- 1
cond <- condition(runif(10), t , x[m])
t <- t + cond
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(cond  * 2), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(Sys.time() - beg)
}
m <- c(100, 1000, 10000, 100000, 1000000, 10000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
stopCluster(cl)
fast
rm(list=ls())
M <- 10000
t_data <- rep(NA, M)
x <- runif(M)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
for (m in 1:M){
cond <- condition(runif(10), t , x[m])
t <-  cond +1
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(cond * 2), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
barplot(table(t_data), xlim = c(1, 25))
rm(list=ls())
set.seed(13112221)
library(parallel)
library(doSNOW)
n_cores <- detectCores()
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
stopping <- function(M){
beg <- Sys.time()
t_data <- rep(NA, M)
x <- runif(M)
for (m in 1:M){
cond <- condition(runif(10), t , x[m])
t <-  cond + 1
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(cond  * 10), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(Sys.time() - beg)
}
m <- c(100, 1000, 10000, 100000, 1000000, 10000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
fast
rm(list=ls())
set.seed(13112221)
library(parallel)
library(doSNOW)
n_cores <- detectCores()
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
stopping <- function(M){
beg <- Sys.time()
t_data <- rep(NA, M)
x <- runif(M)
for (m in 1:M){
cond <- condition(runif(10), t , x[m])
t <-  cond + 1
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(cond  * 100), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(Sys.time() - beg)
}
m <- c(100, 1000, 10000, 100000, 1000000, 10000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
stopCluster(cl)
fast
stopCluster(cl)
# Exercise 1  Stopping time -----------------------------------------------
rm(list=ls())
set.seed(13112221)
library(parallel)
library(doSNOW)
n_cores <- detectCores()
cl <- makeCluster(n_cores, type = 'SOCK')
registerDoSNOW(cl)
condition <- function(vec_y , t , val){
t <- 0
for (i in vec_y){
if (i >  val){ break }
else  t <- t + 1
}
return(t)
}
stopping <- function(M){
beg <- Sys.time()
t_data <- rep(NA, M)
x <- runif(M)
for (m in 1:M){
cond <- condition(runif(10), t , x[m])
t <-  cond + 1
if (cond != 0) {
while ( cond %% 10  == 0 ){
cond <- cond + condition(runif(cond  * 2), t , x[m])
t <- t + cond + 1
}
}
t_data[m] <- t
}
return(Sys.time() - beg)
}
m <- c(100, 1000, 10000, 100000, 1000000, 10000000)
fast <- foreach(i= m, .combine = 'c') %dopar% {lapply(i, stopping)}
stopCluster(cl)
fast
rm(list = ls())    # Clean the environment
library(VGAM)
library(readr)
##### Load the dataset #####
fitness <- read_csv("fitness.csv")   # Read the dataset
n <- nrow(fitness)                   # Number of observations
colnames(fitness) <- c("index" , "Frequences_per_mounth")   # Rename the column
fitness$index <- seq(from = 1 , to = n , by = 1)            # Indexing
##### Plotting & Summary statistics #####
# Historam
par(mfrow = c(1,1))
hist(fitness$Frequences_per_mounth , col = "darkgoldenrod1" ,
main = "Work out" , freq = F , xlab = "times work out",
border = "white")
box()
summary(fitness$Frequences_per_mounth)
# Normalize the data
maximum <- max(fitness$Frequences_per_mounth)
minimun <-  min(fitness$Frequences_per_mounth)
fitness$norm <-  round(( fitness$Frequences_per_mounth -  minimun ) / (maximum - minimun) , 2)
##### Build the privatized function #####
privatized_engine <- function(
data = fitness$norm, m = 15 , h = 1 / m , eps = 0.1  )
{
n = length(data)        # Number of the observations
bins <-  seq(0,1,h)     # Number of bins
intervals <- cut( data, bins, include.lowest = T)
pj_hat <- table(intervals) / n
p_hat <- as.vector(pj_hat / h)
nu <- rlaplace(m, 0, 2/eps)  # Perturbeb data
Dj <- table(intervals) + nu
Dj[Dj < 0] = 0
qj_hat = Dj
if (sum(qj_hat) != 0){qj_hat <- qj_hat / sum(qj_hat)} else {qj_hat <- rep(0, length(qj_hat))}
q_absfre <- round(qj_hat * n , 0 )
Z <- c()         #Build the new dataset
i <- 0
for ( x in q_absfre ){
i <- i + 1
Z <- c(Z, runif(x, bins[i],bins[i+1]))
}
private_dat <- data.frame(Z)
private_dat$index <- seq(from = 1 , to = length(private_dat) , 1)
colnames(private_dat) <- c("privatized_times_norm" , "index")
private_dat$privatized_times <- (private_dat$privatized_times_norm) * maximum
return(private_dat)
}
##### Different set-up ####
m_vec   <- c(  5   ,  10 ,  15 , 20)    # Number of bins
eps_vec <- c( .001 , .01 , .1  ,  1)    # level of privacy
k_vec   <- c(  25  ,  50 ,  75 , 100 )  # (half -  3/4  - all) of the data
##### Run over m let be fixed the other parameters #####
summary_stats_m <- matrix( NA , nrow = length(m_vec) , ncol = 6)
hist_m <- c()
colnames(summary_stats_m) <-  c("Min", "1st Qu" , "Median" , "Mean" , "3rd Qu" , "Max" )
rownames(summary_stats_m) <- m_vec
par(mfrow= c(2,2))
i <- 1
for (x in m_vec){
dataset <- privatized_engine(data = fitness$norm , m = x)
summary_stats_m[i,] <- summary(dataset$privatized_times)
hist(dataset$privatized_times, main = paste(" privatized dataset \n with m set to: " , x ) , xlab = 'times per month' , freq = F , col = "cyan4")
box()
i <- i + 1
}
summary(fitness$Frequences_per_mounth)
summary_stats_m
#### Run over eps let be fixed the other parameters ####
summary_stats_eps <- matrix( NA , nrow = length(eps_vec) , ncol = 6)
hist_eps <- c()
colnames(summary_stats_eps) <-  c("Min", "1st Qu" , "Median" , "Mean" , "3rd Qu" , "Max" )
rownames(summary_stats_eps) <- eps_vec
par(mfrow= c(2,2))
i <- 1
for (x in eps_vec){
dataset <- privatized_engine(data = fitness$norm , eps = x)
summary_stats_m[i,] <- summary(dataset$privatized_times)
hist(dataset$privatized_times, main = paste(" privatized dataset \n with eps set to: " , x ) , xlab = 'times per month' , freq = F , col = "cyan4")
box()
i <- i + 1
}
summary(fitness$Frequences_per_mounth)
summary_stats_m
##### Run over k let be fixed the other parameters #####
summary_stats_k <- matrix( NA , nrow = length(k_vec) , ncol = 6)
colnames(summary_stats_m) <-  c("Min", "1st Qu" , "Median" , "Mean" , "3rd Qu" , "Max" )
rownames(summary_stats_m) <- k_vec
par(mfrow= c(2,2))
i <- 1
for (x in k_vec){
dataset <- privatized_engine(data = fitness$norm[1:x])
summary_stats_m[i,] <- summary(dataset$privatized_times)
hist(dataset$privatized_times, main = paste(" privatized dataset \n with k set to: " , x ) , xlab = 'times per month' , freq = F , col = "cyan4")
box()
i <- i + 1
}
summary(fitness$Frequences_per_mounth)
summary_stats_m
eps_1 <- privatized_engine(eps = .1)
summary(eps_1$privatized_times_norm)
hist(eps_1$privatized_times_norm)
private_dat <- data.frame(Z)
private_dat$index <- seq(from = 1 , to = n -1 , 1)
colnames(private_dat) <- c("privatized_times_norm" , "index")
private_dat
private_dat$privatized_times <- private_dat$privatized_times_norm * maximum
private_dat$privatized_times
hist(private_dat$privatized_times,
col = "turquoise" , border = "white",
main = "Privatized data" , xlab = "Work_out times")
box()
boxplot(private_dat$privatized_times , col = "cyan4",
main = " Privatized Boxplot of times work-out" ,
code = 3, length = .1)
summary(fitness$Frequences_per_mounth)
summary(private_dat$privatized_times)
rm(list = ls())    # Clean the environment
library(VGAM)
library(readr)
##### Load the dataset #####
fitness <- read_csv("fitness.csv")   # Read the dataset
n <- nrow(fitness)                   # Number of observations
##### Load the dataset #####
fitness <- read_csv("fitness.csv")   # Read the dataset
View(fitness)
setwd("~/Desktop/Documents")
setwd("~/Desktop/Documents/GitHub/SDS_HW1")
rm(list = ls())    # Clean the environment
library(VGAM)
library(readr)
##### Load the dataset #####
fitness <- read_csv("fitness.csv")   # Read the dataset
n <- nrow(fitness)                   # Number of observations
fitness
View(fitenss)
View(fitness)
